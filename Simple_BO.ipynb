{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "originalKey": "00018e33-90ca-4f63-b741-fe1fd43ca7db",
    "showInput": false
   },
   "source": [
    "## synthetic Hartmann6 test function. \n",
    "we will attempt to maximize $-f(x)$ to achieve $\\max_{x} -f(x) = 3.32237$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "customOutput": null,
    "executionStartTime": 1668649987115,
    "executionStopTime": 1668649987899,
    "originalKey": "2c0bfbc7-7e42-4601-83ed-4a77270803a8",
    "requestMsgId": "18ccce84-9f39-4c3d-89b1-1e9ed2540859"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import inspect\n",
    "import torch\n",
    "from botorch.test_functions import Hartmann\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.acquisition.analytic import ExpectedImprovement,ProbabilityOfImprovement,UpperConfidenceBound\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.fit import fit_gpytorch_mll,fit_fully_bayesian_model_nuts # TODO\n",
    "from botorch.optim import optimize_acqf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BO parameter - tunable\n",
    "acq_fun = ProbabilityOfImprovement\n",
    "acq_kwargs = {} # conditional para UpperConfidenceBound - 'beta':0.5\n",
    "fit = fit_gpytorch_mll\n",
    "\n",
    "# fixed\n",
    "q = 1\n",
    "init_n = 10\n",
    "num_restarts = 4\n",
    "raw_samples = 128\n",
    "Bo_iter = 50\n",
    "verbose = 10 # int number of iter to show best f so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(x, y, fit, state_dict=None):\n",
    "    model = SingleTaskGP(x, y).to(device)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model).to(device)\n",
    "    if state_dict is not None:\n",
    "        model.load_state_dict(state_dict)\n",
    "    fit(mll);\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem parameter\n",
    "noise = 0.1\n",
    "neg_hartmann6 = Hartmann(negate=True)\n",
    "neg_hartmann6_noise = Hartmann(noise_std=noise, negate=True)\n",
    "bounds = torch.tensor([[0.0] * 6, [1.0] * 6], device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init x,y\n",
    "x = torch.rand(init_n,6,device=device,dtype=dtype)\n",
    "y = neg_hartmann6_noise(x)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best val is tensor([0.2578], device='cuda:0', dtype=torch.float64) at iter 10\n",
      "best val is tensor([0.0216], device='cuda:0', dtype=torch.float64) at iter 20\n",
      "best val is tensor([3.0044], device='cuda:0', dtype=torch.float64) at iter 30\n",
      "best val is tensor([2.9784], device='cuda:0', dtype=torch.float64) at iter 40\n",
      "best val is tensor([3.0451], device='cuda:0', dtype=torch.float64) at iter 50\n"
     ]
    }
   ],
   "source": [
    "model = initialize_model(x, y, fit)\n",
    "for j in range(1,1+Bo_iter):\n",
    "    # set up acqucision fun\n",
    "    if 'best_f' in inspect.signature(acq_fun).parameters:\n",
    "        acq_kwargs['best_f'] = y.max().item()\n",
    "    acq = acq_fun(model,**acq_kwargs)\n",
    "\n",
    "    # optimize over x_next\n",
    "    x_next = optimize_acqf(acq,bounds,q=q,num_restarts=num_restarts,raw_samples=raw_samples)[0].detach()\n",
    "\n",
    "    # try x_next\n",
    "    y_next = neg_hartmann6_noise(x_next)\n",
    "\n",
    "    # update dataset\n",
    "    x = torch.cat([x,x_next])\n",
    "    y = torch.cat([y,y_next[:,None]])\n",
    "\n",
    "    # update model\n",
    "    model = initialize_model(x, y, fit, model.state_dict())\n",
    "    \n",
    "    if j%verbose == 0:\n",
    "        # select from existing x, better for less noisy problem\n",
    "#         argmax_i = y.argmax().item()\n",
    "#         y_best = neg_hartmann6(x[argmax_i])\n",
    "        # select from mean of posterior\n",
    "        mean_fun = lambda x:model(x).mean\n",
    "        x_best = optimize_acqf(mean_fun,bounds,q=1,num_restarts=1,raw_samples=1)[0].detach()\n",
    "        y_best =  neg_hartmann6(x_best)\n",
    "        print('best val is {} at iter {}'.format(y_best.item(),j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dataExplorerConfig": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "outputWidgetContext": {}
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
